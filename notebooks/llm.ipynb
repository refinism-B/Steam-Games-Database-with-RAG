{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51cc398c",
   "metadata": {},
   "source": [
    "## LLM 調用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41c2a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import psycopg2\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.messages import (AIMessageChunk, HumanMessage, SystemMessage,\n",
    "                                ToolMessage)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.tools import tool\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from src.config.constant import (EMBEDDING_MODEL, OLLAMA_LOCAL, OLLAMA_URL,\n",
    "                                 PG_COLLECTION, PROJECT_ROOT, SYSTEM_PROMPT)\n",
    "from src.database import postgreSQL_conn as pgc\n",
    "from src.database.postgreSQL_conn import DB_NAME, PASSWORD, PG_HOST, PORT, USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a9d11ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立embedding連線\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=EMBEDDING_MODEL,\n",
    "    base_url=OLLAMA_URL\n",
    ")\n",
    "\n",
    "# 載入向量資料庫\n",
    "pg_url = pgc.connect_to_pgSQL()\n",
    "vector_store = PGVector(\n",
    "        embeddings=embeddings,\n",
    "        collection_name=PG_COLLECTION,\n",
    "        connection=pg_url,\n",
    "        use_jsonb=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da23c6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立embedding類別\n",
    "class LmStudioEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name, url):\n",
    "        self.model_name = model_name\n",
    "        self.url = url\n",
    "        self.client = OpenAI(base_url=url, api_key=\"lm-studio\")\n",
    "\n",
    "    def embed_query(self, text: str):\n",
    "        response = self.client.embeddings.create(input=text,model=self.model_name)\n",
    "        return response.data[0].embedding\n",
    "\n",
    "    def embed_documents(self, texts: list[str]):\n",
    "        # 回傳多個文件的 embedding\n",
    "        response = self.client.embeddings.create(input=texts,model=self.model_name)\n",
    "        return [x.embedding for x in response.data]\n",
    "        # return [self.model.encode(t).tolist() for t in texts]\n",
    "\n",
    "\n",
    "class stream_chat_bot:\n",
    "    def __init__(self, llm, tools):\n",
    "        self.llm = llm\n",
    "        # 初始化對話機器人，傳入 LLM 與可用工具列表\n",
    "        self.tools = tools\n",
    "        # 將 LLM 綁定（bind）工具，使其具備自動呼叫工具的能力\n",
    "        self.llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "        # 系統提示詞（System Prompt），用來設定 LLM 的角色與行為\n",
    "        system_prompt = SYSTEM_PROMPT\n",
    "        # 初始化訊息列表，第一條訊息是系統指令\n",
    "        self.message = [SystemMessage(system_prompt)]\n",
    "\n",
    "        # 將 LLM 的回應解析為純文字格式的工具\n",
    "        self.str_parser = StrOutputParser()\n",
    "\n",
    "    def _rephrase_query(self, user_input):\n",
    "        \"\"\"\n",
    "        中間層 LLM：將使用者原始輸入轉換為更精準的查詢語句。\n",
    "        \"\"\"\n",
    "        rephrase_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"你是一個提問優化專家。請分析使用者的輸入與對話歷史，\n",
    "            將其轉換為一個『獨立、完整、精準且簡潔』的問題，以便讓後續的搜尋系統能精確執行。\n",
    "\n",
    "            規則：\n",
    "            1. 保留所有關鍵資訊（如：遊戲名稱、日期、特定術語）。\n",
    "            2. 修復錯字或語意不明之處。\n",
    "            3. 如果使用者使用了代名詞（如：他、這件事），請根據歷史紀錄替換成具體內容。\n",
    "            4. 直接輸出優化後的提問文字，不要包含額外的解釋。\"\"\"),\n",
    "            # 傳入部分歷史紀錄增加上下文理解力\n",
    "            (\"placeholder\", \"{history}\"),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "\n",
    "        # 使用原始 LLM 進行快速轉換\n",
    "        rephrase_chain = rephrase_prompt | self.llm | self.str_parser\n",
    "\n",
    "        # 取最近的 3 條紀錄作為參考，避免太長\n",
    "        history_context = self.message[-3:] if len(self.message) > 1 else []\n",
    "\n",
    "        refined_query = rephrase_chain.invoke({\n",
    "            \"history\": history_context,\n",
    "            \"input\": user_input\n",
    "        })\n",
    "        return refined_query\n",
    "\n",
    "    def _summarize_history(self):\n",
    "        \"\"\"\n",
    "        執行摘要邏輯：保留 System Prompt 與最新的 2 條訊息，\n",
    "        將其餘的歷史紀錄壓縮成一段摘要。\n",
    "        \"\"\"\n",
    "        if len(self.message) <= 3:\n",
    "            return\n",
    "\n",
    "        keep_latest = 2\n",
    "        to_summarize = self.message[1:-keep_latest]\n",
    "        recent_messages = self.message[-keep_latest:]\n",
    "\n",
    "        summary_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"你是一個專業的對話秘書。請將下方的對話紀錄精簡壓縮，保留核心重點，減少約 30% 總長度，並以繁體中文撰寫。\"),\n",
    "            (\"placeholder\", \"{content}\")\n",
    "        ])\n",
    "\n",
    "        summary_chain = summary_prompt | self.llm | self.str_parser\n",
    "        summary_text = summary_chain.invoke({\"content\": to_summarize})\n",
    "\n",
    "        self.message = [\n",
    "            SystemMessage(content=self.system_prompt_content),\n",
    "            HumanMessage(content=f\"這是先前的對話摘要：{summary_text}\"),\n",
    "            *recent_messages\n",
    "        ]\n",
    "        print(f\"\\n✨ [系統通知]: 歷史紀錄已精簡完成。\")\n",
    "\n",
    "\n",
    "    def chat_generator(self, text, display_data=False):\n",
    "        \"\"\"\n",
    "        主對話生成函式（生成器形式）。\n",
    "        逐步執行 LLM 回應與工具調用，並即時回傳每一步的結果。\n",
    "        \"\"\"\n",
    "        # 若對話紀錄超過三項，進行摘要\n",
    "        if len(self.message) > 3:\n",
    "            self._summarize_history()\n",
    "\n",
    "        # 進行問題轉譯\n",
    "        refined_text = self._rephrase_query(text)\n",
    "\n",
    "        # 將轉役內容加入訊息列表\n",
    "        self.message.append(HumanMessage(refined_text))\n",
    "\n",
    "        while True:\n",
    "            # 呼叫 LLM，傳入完整訊息歷史\n",
    "            final_ai_message = AIMessageChunk(content=\"\")\n",
    "            for chunk in self.llm_with_tools.stream(self.message):\n",
    "                final_ai_message += chunk\n",
    "                if hasattr(chunk, 'content') and chunk.content:\n",
    "                    yield self.str_parser.invoke(chunk)\n",
    "\n",
    "            response = final_ai_message\n",
    "\n",
    "            # 將 LLM 回應加入訊息列表\n",
    "            self.message.append(response)\n",
    "\n",
    "            # 檢查 LLM 是否要求呼叫工具\n",
    "            is_tools_call = False\n",
    "            for tool_call in response.tool_calls:\n",
    "                is_tools_call = True\n",
    "\n",
    "                if display_data:\n",
    "                    # # 顯示 LLM 要執行的工具名稱與參數\n",
    "                    msg = f'[執行]: {tool_call[\"name\"]}({tool_call[\"args\"]})\\n-----------\\n' #完整訊息\n",
    "                    yield msg  # 使用 yield 讓結果能即時顯示在輸出中\n",
    "\n",
    "                # 實際執行工具（根據工具名稱動態呼叫對應物件）\n",
    "                tool_result = globals()[tool_call['name']].invoke(tool_call['args'])\n",
    "\n",
    "                if display_data:\n",
    "                    # # 顯示工具執行結果\n",
    "                    msg = f'[結果]: {tool_result}\\n-----------\\n'\n",
    "                    yield msg\n",
    "\n",
    "                # 將工具執行結果封裝成 ToolMessage 回傳給 LLM\n",
    "                tool_message = ToolMessage(\n",
    "                    content=str(tool_result),          # 工具執行的文字結果\n",
    "                    name=tool_call[\"name\"],            # 工具名稱\n",
    "                    tool_call_id=tool_call[\"id\"],      # 工具呼叫 ID（讓 LLM 知道對應哪個呼叫）\n",
    "                )\n",
    "                # 將工具回傳結果加入訊息列表，提供 LLM 下一輪參考\n",
    "                self.message.append(tool_message)\n",
    "\n",
    "            # 若這一輪沒有任何工具呼叫，表示 LLM 已經生成最終回覆\n",
    "            if not is_tools_call:\n",
    "                break\n",
    "\n",
    "\n",
    "    def chat(self, text, print_output=False):\n",
    "        \"\"\"\n",
    "        封裝版對話函式。\n",
    "        會收集 chat_generator 的所有輸出，並組合成完整的回覆字串。\n",
    "        \"\"\"\n",
    "        msg = ''\n",
    "        # 逐步取得 chat_generator 的產出內容\n",
    "        for chunk in self.chat_generator(text):\n",
    "            msg += f\"{chunk}\"\n",
    "            if print_output:\n",
    "                print(chunk, end='')\n",
    "        # 回傳最終組合的對話內容\n",
    "        return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a76a96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewGameInput(BaseModel):\n",
    "    question: str = Field(description=\"查詢的問題文字\")\n",
    "    k: int = Field(default=2, description=\"要回傳的文件數量\")\n",
    "\n",
    "\n",
    "@tool(args_schema=FewGameInput)\n",
    "def few_game_rag(question, n=10, k=2):\n",
    "    \"\"\"\n",
    "    當使用者詢問關於『特定 1-2 款遊戲』的詳細資訊時使用。\n",
    "    例如：某款遊戲的背景故事、具體玩法機制、硬體配備要求等。\n",
    "    這會提供非常完整的文本資料。\n",
    "\n",
    "    Args:\n",
    "        question (str): 查詢的問題文字。\n",
    "        n (int): 搜尋子文件的數量。\n",
    "        k (int): 要回傳的文件數量，預設為 2。若有需要可以增加查詢筆數。\n",
    "\n",
    "    Returns:\n",
    "        documents: 檢索到的相似文件列表。\n",
    "    \"\"\"\n",
    "    # 檢索子文件\n",
    "    child_docs = vector_store.similarity_search(question, k=n)\n",
    "\n",
    "    # 提取父文件id\n",
    "    unique_parent_ids = list(dict.fromkeys([\n",
    "        doc.metadata[\"parent_id\"] for doc in child_docs if \"parent_id\" in doc.metadata\n",
    "    ]))\n",
    "\n",
    "    target_ids = unique_parent_ids[:k]\n",
    "    if not target_ids:\n",
    "        return []\n",
    "\n",
    "    # 批次查詢父文件\n",
    "    parent_documents = vector_store.similarity_search(\n",
    "        query=\"\",\n",
    "        k=len(target_ids),\n",
    "        filter={\"doc_id\": {\"$in\": target_ids}} # 假設支援 $in 運算子\n",
    "    )\n",
    "\n",
    "    return parent_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c50381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"選擇主要LLM\"\"\"\n",
    "\n",
    "model_select = input(\"請選擇使用模型:(1.地端gemma3-12b / 2.免費gemini-3-flash / 3.付費gemini-3-flash)\")\n",
    "if str(model_select) == \"1\":\n",
    "    model_name = 'gemma-3-12b-it'\n",
    "\n",
    "    base_url = 'http://192.168.0.109:1234/v1'\n",
    "\n",
    "    llm = ChatOpenAI(\n",
    "        model=model_name,\n",
    "        openai_api_key=\"not-needed\",\n",
    "        openai_api_base=base_url\n",
    "    )\n",
    "\n",
    "elif str(model_select) == \"2\":\n",
    "    API_KEY = os.getenv(\"GOOGLE_API\")\n",
    "    model_name = 'gemini-3-flash-preview'\n",
    "\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=model_name,\n",
    "        google_api_key=API_KEY\n",
    "    )\n",
    "\n",
    "elif str(model_select) == \"3\":\n",
    "    PRICE_API_KEY = os.getenv(\"GOOGLE_API_PRICE\")\n",
    "    model_name = 'gemini-3-flash-preview'\n",
    "\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=model_name,\n",
    "        google_api_key=PRICE_API_KEY\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"請輸入1, 2 或 3 選擇使用模型\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9299b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [few_game_rag]\n",
    "bot = stream_chat_bot(llm, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a872933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《戰慄時空 2》(Half-Life 2) 是電子遊戲史上最具代表性且評價極高的作品之一。以下是根據 Steam 資料庫與相關紀錄為您整理的詳細資訊：\n",
      "\n",
      "### 1. 媒體評分\n",
      "*   **Metacritic 分數**：**96 / 100**。\n",
      "*   此分數代表了媒體的一致盛讚，並使其長期穩居史上評分最高的 PC 遊戲之一。\n",
      "\n",
      "### 2. 玩家評價\n",
      "*   **Steam 評價狀態**：**壓倒性好評 (Overwhelmingly Positive)**。\n",
      "*   **好評率**：高達 **97.7%**。\n",
      "*   **評論數**：累積超過 19 萬則玩家評論，顯示其在推出多年後依然深受社群喜愛。\n",
      "\n",
      "### 3. 電子遊戲史上的影響力與地位\n",
      "《戰慄時空 2》被廣泛認為是「為下一代遊戲奠定框架」的里程碑（PC Gamer 語），其主要貢獻與地位包含：\n",
      "*   **物理引擎的革新**：引入了 Source 引擎與高度互動的物理系統（如著名的「重力槍」），讓環境互動不再只是視覺效果，而是玩法與解謎的核心。\n",
      "*   **敘事手法**：延承了一代「無過場動畫」的沉浸式敘事傳統，讓玩家始終透過主角高登·弗里曼的視角體驗故事，極大提升了代入感。\n",
      "*   **世界觀塑造**：其精緻的世界觀構建（如 17 號城、合成人）與壓抑的烏托邦氛圍，成為了第一人稱射擊遊戲（FPS）敘事的新基準。\n",
      "*   **技術遺產**：作為 Source 引擎的首發作品，它催生了無數經典的 Mod（如《絕對武力：次世代》與《傳送門》的前身），對後世遊戲開發有著極深遠的影響。\n",
      "\n",
      "這款遊戲不僅是 Valve 的巔峰之作，更是許多玩家心中不可動搖的經典神作。如果您對這款遊戲的其他細節（如硬體需求或 DLC 內容）感興趣，隨時歡迎詢問！"
     ]
    }
   ],
   "source": [
    "for x in bot.chat_generator(\"半條命2的評價如何\", display_data=False):\n",
    "    print(x, end='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steam-games-database-with-rag-1sd27EX4-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
